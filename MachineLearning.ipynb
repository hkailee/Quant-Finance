{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha VAntage API \"NBXHMWG8ZJ80E921\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trading-calendars\n",
      "Requirement not upgraded as not directly required: toolz in /Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages (from trading-calendars) (0.9.0)\n",
      "Requirement not upgraded as not directly required: lru-dict in /Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages (from trading-calendars) (1.1.4)\n",
      "Requirement not upgraded as not directly required: numpy in /Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages (from trading-calendars) (1.14.1)\n",
      "Requirement not upgraded as not directly required: pandas in /Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages (from trading-calendars) (0.22.0)\n",
      "Requirement not upgraded as not directly required: pytz in /Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages (from trading-calendars) (2017.3)\n",
      "Requirement not upgraded as not directly required: python-dateutil>=2 in /Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages (from pandas->trading-calendars) (2.7.3)\n",
      "Requirement not upgraded as not directly required: six>=1.5 in /Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages (from python-dateutil>=2->pandas->trading-calendars) (1.11.0)\n",
      "Installing collected packages: trading-calendars\n",
      "  Found existing installation: trading-calendars 1.5.1\n",
      "    Uninstalling trading-calendars-1.5.1:\n",
      "      Successfully uninstalled trading-calendars-1.5.1\n",
      "Successfully installed trading-calendars-1.7.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U trading-calendars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages used commonly\n",
    "import bs4 as bs\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import pandas_market_calendars as mcal\n",
    "import shutil\n",
    "from time import sleep\n",
    "# from sklearn import svm, cross_validation, neighbors\n",
    "# from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "\n",
    "# Import supplementary data import code tools.py\n",
    "from utils.sqlitedb import *\n",
    "from utils.data_preparation import get_trading_close_holidays, process_raw_data, \\\n",
    "        process_raw_data_breakout, ingest_by_zipline, filling_gaps_of_raw_data, \\\n",
    "        combine_csvs, get_data_targeted, traverse, process_raw_data_breakout_appending\n",
    "\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "ts = TimeSeries(key='NBXHMWG8ZJ80E921', output_format='pandas', indexing_type='date', retries=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have CSCO\n",
      "Already have UAL\n",
      "Already have TROW\n",
      "Already have ISRG\n",
      "Already have PRGO\n",
      "Already have TPR\n",
      "Already have DVN\n",
      "Already have CE\n",
      "Already have MRO\n",
      "Already have BA\n",
      "Already have VRTX\n",
      "Already have GILD\n",
      "Already have NLSN\n",
      "Already have EQIX\n",
      "Already have TIF\n",
      "Already have MDT\n",
      "Already have V\n",
      "Already have A\n",
      "Already have FLT\n",
      "Already have MO\n",
      "Already have WCG\n",
      "Already have SWKS\n",
      "Already have MCHP\n",
      "Already have CDNS\n",
      "Already have MSCI\n",
      "Already have CHTR\n",
      "Already have EIX\n",
      "Already have BBY\n",
      "Already have WBA\n",
      "Already have HCA\n",
      "Already have AJG\n",
      "Already have DTE\n",
      "Already have C\n",
      "Already have T\n",
      "Already have CF\n",
      "Already have DISH\n",
      "Already have MGM\n",
      "Already have HUM\n",
      "Already have CBOE\n",
      "Already have WU\n",
      "Already have APH\n",
      "Already have SYY\n",
      "Already have MSI\n",
      "Already have FCX\n",
      "Already have ADM\n",
      "Already have LH\n",
      "Already have STI\n",
      "Already have UTX\n",
      "Already have PKI\n",
      "Already have LNT\n",
      "Already have BAC\n",
      "Already have LNC\n",
      "Already have PSX\n",
      "Already have GPN\n",
      "Already have PPG\n",
      "Already have RHT\n",
      "Already have IRM\n",
      "Already have ESS\n",
      "Already have NOV\n",
      "Already have HAL\n",
      "Already have STZ\n",
      "Already have FLS\n",
      "Already have ADI\n",
      "Already have F\n",
      "Already have HOG\n",
      "Already have ADBE\n",
      "Already have CPRT\n",
      "Already have TDG\n",
      "Already have TFX\n",
      "Already have ULTA\n",
      "Already have ARE\n",
      "Already have SYK\n",
      "Already have CB\n",
      "Already have TSN\n",
      "Already have FLR\n",
      "Already have PEP\n",
      "Already have PEG\n",
      "Already have LLY\n",
      "Already have COST\n",
      "Already have REG\n",
      "Already have LLL\n",
      "Already have LOW\n",
      "Already have MDLZ\n",
      "Already have BKNG\n",
      "Already have FMC\n",
      "Already have HCP\n",
      "Already have XEL\n",
      "Already have AIZ\n",
      "Already have CERN\n",
      "Already have MET\n",
      "Already have DLR\n",
      "Already have XRAY\n",
      "Already have FAST\n",
      "Already have TJX\n",
      "Already have SNA\n",
      "Already have MPC\n",
      "Already have BR\n",
      "Already have D\n",
      "Already have MRK\n",
      "Already have STX\n",
      "Already have NOC\n",
      "Already have BXP\n",
      "Already have IPG\n",
      "Already have UNP\n",
      "Already have ORCL\n",
      "Already have ECL\n",
      "Already have ETR\n",
      "Already have EBAY\n",
      "Already have SBUX\n",
      "Already have IR\n",
      "Already have AMT\n",
      "Already have INTU\n",
      "Already have DRE\n",
      "Already have JEC\n",
      "Already have CMA\n",
      "Already have IPGP\n",
      "Already have PG\n",
      "Already have CAT\n",
      "Already have MCD\n",
      "Already have MNST\n",
      "Already have AMZN\n",
      "Already have INTC\n",
      "Already have PNR\n",
      "Already have GLW\n",
      "Already have BDX\n",
      "Already have KMI\n",
      "Already have PWR\n",
      "Already have EXR\n",
      "Already have WELL\n",
      "Already have HOLX\n",
      "Already have EXPD\n",
      "Already have GM\n",
      "Already have TXN\n",
      "Already have VRSK\n",
      "Already have SJM\n",
      "Already have TMO\n",
      "Already have OXY\n",
      "Already have RL\n",
      "Already have CCI\n",
      "Already have MMM\n",
      "Already have MOS\n",
      "Already have FTNT\n",
      "Already have HSY\n",
      "Already have JNPR\n",
      "Already have DHI\n",
      "Already have ED\n",
      "Already have ES\n",
      "Already have ADSK\n",
      "Already have IP\n",
      "Already have EXPE\n",
      "Already have KO\n",
      "Already have PCAR\n",
      "Already have WDC\n",
      "Already have NEE\n",
      "Already have UPS\n",
      "Already have FLIR\n",
      "Already have LEG\n",
      "Already have EMR\n",
      "Already have MSFT\n",
      "Already have ANSS\n",
      "Already have CTAS\n",
      "Already have UDR\n",
      "Already have RTN\n",
      "Already have WEC\n",
      "Already have AME\n",
      "Already have HP\n",
      "Already have IT\n",
      "Already have ACN\n",
      "Already have VRSN\n",
      "Already have EW\n",
      "Already have FL\n",
      "Already have CMG\n",
      "Already have AWK\n",
      "Already have COO\n",
      "Already have SHW\n",
      "Already have HPQ\n",
      "Already have AMAT\n",
      "Already have CCL\n",
      "Already have MLM\n",
      "Already have TMK\n",
      "Already have AVY\n",
      "Already have AAP\n",
      "Already have ATVI\n",
      "Already have EA\n",
      "Already have DE\n",
      "Already have SPG\n",
      "Already have AMD\n",
      "Already have MYL\n",
      "Already have KLAC\n",
      "Already have NDAQ\n",
      "Already have URI\n",
      "Already have WHR\n",
      "Already have PNC\n",
      "Already have KMX\n",
      "Already have BIIB\n",
      "Already have NVDA\n",
      "Already have CHRW\n",
      "Already have ROP\n",
      "Already have IDXX\n",
      "Already have EXC\n",
      "Already have HES\n",
      "Already have HD\n",
      "Already have ALB\n",
      "Already have VLO\n",
      "Already have AON\n",
      "Already have FDX\n",
      "Already have DG\n",
      "Already have HIG\n",
      "Already have JEF\n",
      "Already have CMS\n",
      "Already have CAG\n",
      "Already have INCY\n",
      "Already have SCHW\n",
      "Already have HSIC\n",
      "Already have AZO\n",
      "Already have AXP\n",
      "Already have DFS\n",
      "Already have SEE\n",
      "Already have HRL\n",
      "Already have SO\n",
      "Already have FRT\n",
      "Already have ZBH\n",
      "Already have FRC\n",
      "Already have CME\n",
      "Already have XOM\n",
      "Already have AMP\n",
      "Already have AMG\n",
      "Already have CVX\n",
      "Already have ETFC\n",
      "Already have CMCSA\n",
      "Already have PNW\n",
      "Already have ICE\n",
      "Already have CTXS\n",
      "Already have TRIP\n",
      "Already have BEN\n",
      "Already have DISCK\n",
      "Already have UHS\n",
      "Already have EMN\n",
      "Already have SBAC\n",
      "Already have ROK\n",
      "Already have NRG\n",
      "Already have NSC\n",
      "Already have NKE\n",
      "Already have FIS\n",
      "Already have VTR\n",
      "Already have MAS\n",
      "Already have RF\n",
      "Already have CELG\n",
      "Already have TAP\n",
      "Already have MAR\n",
      "Already have XYL\n",
      "Already have CMI\n",
      "Already have FB\n",
      "Already have MTD\n",
      "Already have VAR\n",
      "Already have KR\n",
      "Already have PLD\n",
      "Already have IBM\n",
      "Already have USB\n",
      "Already have BSX\n",
      "Already have LKQ\n",
      "Already have FBHS\n",
      "Already have ITW\n",
      "Already have EOG\n",
      "Already have PVH\n",
      "Already have KMB\n",
      "Already have SPGI\n",
      "Already have NEM\n",
      "Already have SYMC\n",
      "Already have WFC\n",
      "Already have EL\n",
      "Already have GS\n",
      "Already have GD\n",
      "Already have CNP\n",
      "Already have PM\n",
      "Already have RE\n",
      "Already have MCO\n",
      "Already have CLX\n",
      "Already have CAH\n",
      "Already have CBS\n",
      "Already have HRB\n",
      "Already have DGX\n",
      "Already have AVB\n",
      "Already have DIS\n",
      "Already have GE\n",
      "Already have HII\n",
      "Already have ALL\n",
      "Already have ETN\n",
      "Already have ALGN\n",
      "Already have NFLX\n",
      "Already have LEN\n",
      "Already have FITB\n",
      "Already have GWW\n",
      "Already have NTRS\n",
      "Already have CVS\n",
      "Already have CTL\n",
      "Already have AOS\n",
      "Already have FE\n",
      "Already have ABC\n",
      "Already have JPM\n",
      "Already have ABT\n",
      "Already have CXO\n",
      "Already have OMC\n",
      "Already have COF\n",
      "Already have TSCO\n",
      "Already have PH\n",
      "Already have HST\n",
      "Already have JBHT\n",
      "Already have ATO\n",
      "Already have MAC\n",
      "Already have COP\n",
      "Already have DHR\n",
      "Already have COG\n",
      "Already have MAT\n",
      "Already have CNC\n",
      "Already have MCK\n",
      "Already have TXT\n",
      "Already have MTB\n",
      "Already have HFC\n",
      "Already have DISCA\n",
      "Already have AKAM\n",
      "Already have ROL\n",
      "Already have RMD\n",
      "Already have GOOGL\n",
      "Already have PAYX\n",
      "Already have ALK\n",
      "Already have DRI\n",
      "Already have ILMN\n",
      "Already have AAL\n",
      "Already have XLNX\n",
      "Already have MAA\n",
      "Already have HRS\n",
      "Already have MMC\n",
      "Already have FFIV\n",
      "Already have VNO\n",
      "Already have CINF\n",
      "Already have VMC\n",
      "Already have SRE\n",
      "Already have ORLY\n",
      "Already have IVZ\n",
      "Already have RCL\n",
      "Already have ARNC\n",
      "Already have PXD\n",
      "Already have SNPS\n",
      "Already have SIVB\n",
      "Already have YUM\n",
      "Already have KSS\n",
      "Already have PFE\n",
      "Already have AIV\n",
      "Already have AVGO\n",
      "Already have DUK\n",
      "Already have REGN\n",
      "Already have CL\n",
      "Already have VFC\n",
      "Already have VZ\n",
      "Already have NKTR\n",
      "Already have APC\n",
      "Already have JCI\n",
      "Already have AMGN\n",
      "Already have TEL\n",
      "Already have JKHY\n",
      "Already have ADP\n",
      "Already have LB\n",
      "Already have STT\n",
      "Already have RSG\n",
      "Already have IFF\n",
      "Already have ANTM\n",
      "Already have GPS\n",
      "Already have BLL\n",
      "Already have QCOM\n",
      "Already have LYB\n",
      "Already have GIS\n",
      "Already have PHM\n",
      "Already have ROST\n",
      "Already have LUV\n",
      "Already have ALXN\n",
      "Already have XEC\n",
      "Already have MS\n",
      "Already have CPB\n",
      "Already have OKE\n",
      "Already have BK\n",
      "Already have CHD\n",
      "Already have SLG\n",
      "Already have MHK\n",
      "Already have DAL\n",
      "Already have APA\n",
      "Already have K\n",
      "Already have JWN\n",
      "Already have AFL\n",
      "Already have ADS\n",
      "Already have CSX\n",
      "Already have NI\n",
      "Already have PFG\n",
      "Already have ZION\n",
      "Already have RJF\n",
      "Already have HBAN\n",
      "Already have UNH\n",
      "Already have PRU\n",
      "Already have GPC\n",
      "Already have FISV\n",
      "Already have WMB\n",
      "Already have EQR\n",
      "Already have MXIM\n",
      "Already have PBCT\n",
      "Already have KSU\n",
      "Already have DVA\n",
      "Already have AIG\n",
      "Already have MA\n",
      "Already have HBI\n",
      "Already have HON\n",
      "Already have O\n",
      "Already have TTWO\n",
      "Already have AES\n",
      "Already have SLB\n",
      "Already have XRX\n",
      "Already have TGT\n",
      "Already have AAPL\n",
      "Already have MKC\n",
      "Already have WY\n",
      "Already have APD\n",
      "Already have GRMN\n",
      "Already have AEE\n",
      "Already have DLTR\n",
      "Already have HAS\n",
      "Already have WMT\n",
      "Already have NTAP\n",
      "Already have BBT\n",
      "Already have KIM\n",
      "Already have BAX\n",
      "Already have LMT\n",
      "Already have ABMD\n",
      "Already have KEY\n",
      "Already have UNM\n",
      "Already have BMY\n",
      "Already have PSA\n",
      "Already have WYNN\n",
      "Already have RHI\n",
      "Already have EFX\n",
      "Already have NUE\n",
      "Already have PKG\n",
      "Already have NBL\n",
      "Already have WAB\n",
      "Already have CTSH\n",
      "Already have SWK\n",
      "Already have MU\n",
      "Already have TRV\n",
      "Already have L\n",
      "Already have VIAB\n",
      "Already have AEP\n",
      "Already have CI\n",
      "Already have CPRI\n",
      "Already have JNJ\n",
      "Already have WM\n",
      "Already have DOV\n",
      "Already have FTI\n",
      "Already have AGN\n",
      "Already have M\n",
      "Already have TSS\n",
      "Already have CRM\n",
      "Already have PGR\n",
      "Already have WAT\n",
      "Already have BWA\n",
      "Already have LRCX\n",
      "Already have NWL\n",
      "Already have UAA\n",
      "Already have BLK\n",
      "Already have PPL\n"
     ]
    }
   ],
   "source": [
    "# getting data as of date\n",
    "for i in range(1):\n",
    "    get_data_targeted()\n",
    "#     sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_raw_data_breakout_appending(enddate='2019-04-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABBV was excluded as its first tick was collected from 2013-01-02\n",
      "ALLE was excluded as its first tick was collected from 2013-11-18\n",
      "GOOG was excluded as its first tick was collected from 2014-03-27\n",
      "ANET was excluded as its first tick was collected from 2014-06-06\n",
      "BHGE was excluded as its first tick was collected from 2017-07-05\n",
      "CBRE was excluded as its first tick was collected from 2018-03-19\n",
      "CFG was excluded as its first tick was collected from 2014-09-24\n",
      "COTY was excluded as its first tick was collected from 2013-06-13\n",
      "FANG was excluded as its first tick was collected from 2012-10-12\n",
      "DWDP was excluded as its first tick was collected from 2017-08-03\n",
      "DXC was excluded as its first tick was collected from 2017-02-01\n",
      "EVRG was excluded as its first tick was collected from 2018-06-04\n",
      "FTV was excluded as its first tick was collected from 2016-07-01\n",
      "HPE was excluded as its first tick was collected from 2015-10-19\n",
      "HLT was excluded as its first tick was collected from 2013-12-12\n",
      "INFO was excluded as its first tick was collected from 2014-06-19\n",
      "IQV was excluded as its first tick was collected from 2013-05-09\n",
      "KEYS was excluded as its first tick was collected from 2014-10-20\n",
      "KHC was excluded as its first tick was collected from 2015-07-06\n",
      "LW was excluded as its first tick was collected from 2016-11-10\n",
      "LIN was excluded as its first tick was collected from 2018-10-01\n",
      "NWSA was excluded as its first tick was collected from 2013-06-19\n",
      "NWS was excluded as its first tick was collected from 2013-06-19\n",
      "NCLH was excluded as its first tick was collected from 2013-01-18\n",
      "PYPL was excluded as its first tick was collected from 2015-07-20\n",
      "QRVO was excluded as its first tick was collected from 2015-01-02\n",
      "SYF was excluded as its first tick was collected from 2014-07-31\n",
      "TWTR was excluded as its first tick was collected from 2013-11-07\n",
      "FOXA was excluded as its first tick was collected from 2019-03-12\n",
      "FOX was excluded as its first tick was collected from 2019-03-13\n",
      "UA was excluded as its first tick was collected from 2016-04-07\n",
      "WRK was excluded as its first tick was collected from 2015-06-24\n",
      "WLTW was excluded as its first tick was collected from 2016-01-05\n",
      "ZTS was excluded as its first tick was collected from 2013-02-01\n"
     ]
    }
   ],
   "source": [
    "with open('sp500ticker.pickle', 'rb') as f:\n",
    "    tickers = pickle.load(f)\n",
    "process_raw_data_breakout(tickers, startdate='2012-05-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/empyrical/utils.py:32: UserWarning: Unable to import pandas_datareader. Suppressing import error and continuing. All data reading functionality will raise errors; but has been deprecated and will be removed in a later version.\n",
      "  warnings.warn(msg)\n",
      "\u001b[?25lLoading custom pricing data:   [------------------------------------]    0% | A: sid 0\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  0 | AAL: sid 1\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  1 | AAP: sid 2\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  2 | AAPL: sid 3\n",
      "\u001b[?25lLoading custom pricing data:   [------------------------------------]    1% | ABC: sid 4\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  4 | ABMD: sid 5\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  5 | ABT: sid 6\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  6 | ACN: sid 7\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  7 | ADBE: sid 8\n",
      "\u001b[?25lLoading custom pricing data:   [------------------------------------]    2% | ADI: sid 9\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  9 | ADM: sid 10\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  10 | ADP: sid 11\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  11 | ADS: sid 12\n",
      "\u001b[?25lLoading custom pricing data:   [#-----------------------------------]    2% | ADSK: sid 13\n",
      "\u001b[?25lLoading custom pricing data:   [#-----------------------------------]    3% | AEE: sid 14\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  14 | AEP: sid 15\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  15 | AES: sid 16\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  16 | AFL: sid 17\n",
      "\u001b[?25lLoading custom pricing data:   [#-----------------------------------]    4% | AGN: sid 18\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  18 | AIG: sid 19\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  19 | AIV: sid 20\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  20 | AIZ: sid 21\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  21 | AJG: sid 22\n",
      "\u001b[?25lLoading custom pricing data:   [#-----------------------------------]    5% | AKAM: sid 23\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  23 | ALB: sid 24\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  24 | ALGN: sid 25\n",
      "\u001b[?25lLoading custom pricing data:   [##----------------------------------]    5%  0d 00:00:17 | ALK: sid 26\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------#--------]  26 | ALL: sid 27\n",
      "\u001b[?25lLoading custom pricing data:   [##----------------------------------]    6%  0d 00:00:17 | ALXN: sid 28\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------#----------]  28 | AMAT: sid 29\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------#----------]  29 | AMD: sid 30\n",
      "\u001b[?25lMerging daily equity files:  [------------------------#-----------]  30 | AME: sid 31\n",
      "\u001b[?25lLoading custom pricing data:   [##----------------------------------]    7%  0d 00:00:17 | AMG: sid 32\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------#------------]  32 | AMGN: sid 33\n",
      "\u001b[?25lMerging daily equity files:  [----------------------#-------------]  33 | AMP: sid 34\n",
      "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  34 | AMT: sid 35\n",
      "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  35 | AMZN: sid 36\n",
      "\u001b[?25lLoading custom pricing data:   [##----------------------------------]    8%  0d 00:00:17 | ANSS: sid 37\n",
      "\u001b[?25lLoading custom pricing data:   [##----------------------------------]    8%  0d 00:00:16 | ANTM: sid 38\n",
      "\u001b[?25lLoading custom pricing data:   [###---------------------------------]    8%  0d 00:00:16 | AON: sid 39\n",
      "\u001b[?25lMerging daily equity files:  [------------------#-----------------]  39 | AOS: sid 40\n",
      "\u001b[?25lMerging daily equity files:  [-----------------#------------------]  40 | APA: sid 41\n",
      "\u001b[?25lLoading custom pricing data:   [###---------------------------------]    9%  0d 00:00:16 | APC: sid 42\n",
      "\u001b[?25lMerging daily equity files:  [----------------#-------------------]  42 | APD: sid 43\n",
      "\u001b[?25lMerging daily equity files:  [---------------#--------------------]  43 | APH: sid 44\n",
      "\u001b[?25lMerging daily equity files:  [---------------#--------------------]  44 | ARE: sid 45\n",
      "\u001b[?25lLoading custom pricing data:   [###---------------------------------]   10%  0d 00:00:16 | ARNC: sid 46\n",
      "\u001b[?25lMerging daily equity files:  [-------------#----------------------]  46 | ATO: sid 47\n",
      "\u001b[?25lMerging daily equity files:  [-------------#----------------------]  47 | ATVI: sid 48\n",
      "\u001b[?25lMerging daily equity files:  [------------#-----------------------]  48 | AVB: sid 49\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  49 | AVGO: sid 50\n",
      "\u001b[?25lLoading custom pricing data:   [###---------------------------------]   11%  0d 00:00:16 | AVY: sid 51\n",
      "\u001b[?25lLoading custom pricing data:   [####--------------------------------]   11%  0d 00:00:16 | AWK: sid 52\n",
      "\u001b[?25lMerging daily equity files:  [---------#--------------------------]  52 | AXP: sid 53\n",
      "\u001b[?25lMerging daily equity files:  [--------#---------------------------]  53 | AZO: sid 54\n",
      "\u001b[?25lMerging daily equity files:  [--------#---------------------------]  54 | BA: sid 55\n",
      "\u001b[?25lLoading custom pricing data:   [####--------------------------------]   12%  0d 00:00:16 | BAC: sid 56\n",
      "\u001b[?25lMerging daily equity files:  [-------#----------------------------]  56 | BAX: sid 57\n",
      "\u001b[?25lMerging daily equity files:  [------#-----------------------------]  57 | BBT: sid 58\n",
      "\u001b[?25lMerging daily equity files:  [------#-----------------------------]  58 | BBY: sid 59\n",
      "\u001b[?25lLoading custom pricing data:   [####--------------------------------]   13%  0d 00:00:16 | BDX: sid 60\n",
      "\u001b[?25lMerging daily equity files:  [-----#------------------------------]  60 | BEN: sid 61\n",
      "\u001b[?25lMerging daily equity files:  [----#-------------------------------]  61 | BF-B: sid 62\n",
      "\u001b[?25lMerging daily equity files:  [----#-------------------------------]  62 | BIIB: sid 63\n",
      "\u001b[?25lMerging daily equity files:  [---#--------------------------------]  63 | BK: sid 64\n",
      "\u001b[?25lLoading custom pricing data:   [#####-------------------------------]   14%  0d 00:00:16 | BKNG: sid 65\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  65 | BLK: sid 66\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  66 | BLL: sid 67\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  67 | BMY: sid 68\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  68 | BR: sid 69\n",
      "\u001b[?25lLoading custom pricing data:   [#####-------------------------------]   15%  0d 00:00:16 | BRK.B: sid 70\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  70 | BSX: sid 71\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  71 | BWA: sid 72\n",
      "\u001b[?25lLoading custom pricing data:   [#####-------------------------------]   15%  0d 00:00:15 | BXP: sid 73\n",
      "\u001b[?25lLoading custom pricing data:   [#####-------------------------------]   15%  0d 00:00:16 | C: sid 74\n",
      "\u001b[?25lLoading custom pricing data:   [#####-------------------------------]   16%  0d 00:00:16 | CAG: sid 75\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  75 | CAH: sid 76\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  76 | CAT: sid 77\n",
      "\u001b[?25lLoading custom pricing data:   [######------------------------------]   16%  0d 00:00:16 | CB: sid 78\n",
      "\u001b[?25lLoading custom pricing data:   [######------------------------------]   17%  0d 00:00:16 | CBOE: sid 79\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  79 | CBS: sid 80\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  80 | CCI: sid 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  81 | CCL: sid 82\n",
      "\u001b[?25lLoading custom pricing data:   [######------------------------------]   17%  0d 00:00:15 | CDNS: sid 83\n",
      "\u001b[?25lLoading custom pricing data:   [######------------------------------]   18%  0d 00:00:15 | CE: sid 84\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  84 | CELG: sid 85\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  85 | CERN: sid 86\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  86 | CF: sid 87\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  87 | CHD: sid 88\n",
      "\u001b[?25lLoading custom pricing data:   [######------------------------------]   19%  0d 00:00:15 | CHRW: sid 89\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  89 | CHTR: sid 90\n",
      "\u001b[?25lLoading custom pricing data:   [#######-----------------------------]   19%  0d 00:00:15 | CI: sid 91\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  91 | CINF: sid 92\n",
      "\u001b[?25lLoading custom pricing data:   [#######-----------------------------]   20%  0d 00:00:15 | CL: sid 93\n",
      "\u001b[?25lMerging daily equity files:  [---#--------------------------------]  93 | CLX: sid 94\n",
      "\u001b[?25lMerging daily equity files:  [---#--------------------------------]  94 | CMA: sid 95\n",
      "\u001b[?25lMerging daily equity files:  [---#--------------------------------]  95 | CMCSA: sid 96\n",
      "\u001b[?25lMerging daily equity files:  [----#-------------------------------]  96 | CME: sid 97\n",
      "\u001b[?25lLoading custom pricing data:   [#######-----------------------------]   21%  0d 00:00:15 | CMG: sid 98\n",
      "\u001b[?25lMerging daily equity files:  [-----#------------------------------]  98 | CMI: sid 99\n",
      "\u001b[?25lMerging daily equity files:  [------#-----------------------------]  99 | CMS: sid 100\n",
      "\u001b[?25lMerging daily equity files:  [------#-----------------------------]  100 | CNC: sid 101\n",
      "\u001b[?25lMerging daily equity files:  [-------#----------------------------]  101 | CNP: sid 102\n",
      "\u001b[?25lLoading custom pricing data:   [#######-----------------------------]   22%  0d 00:00:15 | COF: sid 103\n",
      "\u001b[?25lLoading custom pricing data:   [########----------------------------]   22%  0d 00:00:15 | COG: sid 104\n",
      "\u001b[?25lMerging daily equity files:  [---------#--------------------------]  104 | COO: sid 105\n",
      "\u001b[?25lMerging daily equity files:  [---------#--------------------------]  105 | COP: sid 106\n",
      "\u001b[?25lLoading custom pricing data:   [########----------------------------]   23%  0d 00:00:15 | COST: sid 107\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  107 | CPB: sid 108\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  108 | CPRI: sid 109\n",
      "\u001b[?25lMerging daily equity files:  [------------#-----------------------]  109 | CPRT: sid 110\n",
      "\u001b[?25lMerging daily equity files:  [-------------#----------------------]  110 | CRM: sid 111\n",
      "\u001b[?25lLoading custom pricing data:   [########----------------------------]   24%  0d 00:00:15 | CSCO: sid 112\n",
      "\u001b[?25lMerging daily equity files:  [----------------#-------------------]  112 | CSX: sid 113\n",
      "\u001b[?25lMerging daily equity files:  [-----------------#------------------]  113 | CTAS: sid 114\n",
      "\u001b[?25lMerging daily equity files:  [------------------#-----------------]  114 | CTL: sid 115\n",
      "\u001b[?25lMerging daily equity files:  [-------------------#----------------]  115 | CTSH: sid 116\n",
      "\u001b[?25lLoading custom pricing data:   [#########---------------------------]   25%  0d 00:00:15 | CTXS: sid 117\n",
      "\u001b[?25lMerging daily equity files:  [--------------------#---------------]  117 | CVS: sid 118\n",
      "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  118 | CVX: sid 119\n",
      "\u001b[?25lMerging daily equity files:  [----------------------#-------------]  119 | CXO: sid 120\n",
      "\u001b[?25lLoading custom pricing data:   [#########---------------------------]   26%  0d 00:00:15 | D: sid 121\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------#------------]  121 | DAL: sid 122\n",
      "\u001b[?25lMerging daily equity files:  [------------------------#-----------]  122 | DE: sid 123\n",
      "\u001b[?25lLoading custom pricing data:   [#########---------------------------]   26%  0d 00:00:14 | DFS: sid 124\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------#----------]  124 | DG: sid 125\n",
      "\u001b[?25lLoading custom pricing data:   [#########---------------------------]   27%  0d 00:00:14 | DGX: sid 126\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------#---------]  126 | DHI: sid 127\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------#--------]  127 | DHR: sid 128\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------#-------]  128 | DIS: sid 129\n",
      "\u001b[?25lLoading custom pricing data:   [##########--------------------------]   27%  0d 00:00:14 | DISCA: sid 130\n",
      "\u001b[?25lLoading custom pricing data:   [##########--------------------------]   28%  0d 00:00:14 | DISCK: sid 131\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  131 | DISH: sid 132\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  132 | DLR: sid 133\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------------#---]  133 | DLTR: sid 134\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------------#---]  134 | DOV: sid 135\n",
      "\u001b[?25lLoading custom pricing data:   [##########--------------------------]   29%  0d 00:00:14 | DRE: sid 136\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  136 | DRI: sid 137\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  137 | DTE: sid 138\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  138 | DUK: sid 139\n",
      "\u001b[?25lLoading custom pricing data:   [##########--------------------------]   30%  0d 00:00:14 | DVA: sid 140\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  140 | DVN: sid 141\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  141 | EA: sid 142\n",
      "\u001b[?25lLoading custom pricing data:   [###########-------------------------]   30%  0d 00:00:14 | EBAY: sid 143\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  143 | ECL: sid 144\n",
      "\u001b[?25lLoading custom pricing data:   [###########-------------------------]   31%  0d 00:00:14 | ED: sid 145\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  145 | EFX: sid 146\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  146 | EIX: sid 147\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  147 | EL: sid 148\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  148 | EMN: sid 149\n",
      "\u001b[?25lLoading custom pricing data:   [###########-------------------------]   32%  0d 00:00:14 | EMR: sid 150\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  150 | EOG: sid 151\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  151 | EQIX: sid 152\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  152 | EQR: sid 153\n",
      "\u001b[?25lLoading custom pricing data:   [###########-------------------------]   33%  0d 00:00:14 | ES: sid 154\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  154 | ESS: sid 155\n",
      "\u001b[?25lLoading custom pricing data:   [############------------------------]   33%  0d 00:00:13 | ETFC: sid 156\n",
      "\u001b[?25lLoading custom pricing data:   [############------------------------]   33%  0d 00:00:14 | ETN: sid 157\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  157 | ETR: sid 158\n",
      "\u001b[?25lLoading custom pricing data:   [############------------------------]   34%  0d 00:00:14 | EW: sid 159\n",
      "\u001b[?25lLoading custom pricing data:   [############------------------------]   34%  0d 00:00:13 | EXC: sid 160\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  160 | EXPD: sid 161\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------------#---]  161 | EXPE: sid 162\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------------#---]  162 | EXR: sid 163\n",
      "\u001b[?25lLoading custom pricing data:   [############------------------------]   35%  0d 00:00:13 | F: sid 164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  164 | FAST: sid 165\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------#-----]  165 | FB: sid 166\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------#-----]  166 | FBHS: sid 167\n",
      "\u001b[?25lLoading custom pricing data:   [############------------------------]   36%  0d 00:00:13 | FCX: sid 168\n",
      "\u001b[?25lLoading custom pricing data:   [#############-----------------------]   36%  0d 00:00:13 | FDX: sid 169\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------#-------]  169 | FE: sid 170\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------#--------]  170 | FFIV: sid 171\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------#---------]  171 | FIS: sid 172\n",
      "\u001b[?25lLoading custom pricing data:   [#############-----------------------]   37%  0d 00:00:13 | FISV: sid 173\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------#----------]  173 | FITB: sid 174\n",
      "\u001b[?25lMerging daily equity files:  [------------------------#-----------]  174 | FL: sid 175\n",
      "\u001b[?25lMerging daily equity files:  [------------------------#-----------]  175 | FLIR: sid 176\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------#------------]  176 | FLR: sid 177\n",
      "\u001b[?25lLoading custom pricing data:   [#############-----------------------]   38%  0d 00:00:13 | FLS: sid 178\n",
      "\u001b[?25lMerging daily equity files:  [------------------#-----------------]  178 | FLT: sid 179\n",
      "\u001b[?25lMerging daily equity files:  [------------------#-----------------]  179 | FMC: sid 180\n",
      "\u001b[?25lMerging daily equity files:  [-----------------#------------------]  180 | FRC: sid 181\n",
      "\u001b[?25lLoading custom pricing data:   [##############----------------------]   39%  0d 00:00:13 | FRT: sid 182\n",
      "\u001b[?25lMerging daily equity files:  [---------------#--------------------]  182 | FTI: sid 183\n",
      "\u001b[?25lMerging daily equity files:  [--------------#---------------------]  183 | FTNT: sid 184\n",
      "\u001b[?25lMerging daily equity files:  [--------------#---------------------]  184 | GD: sid 185\n",
      "\u001b[?25lMerging daily equity files:  [-------------#----------------------]  185 | GE: sid 186\n",
      "\u001b[?25lLoading custom pricing data:   [##############----------------------]   40%  0d 00:00:13 | GILD: sid 187\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  187 | GIS: sid 188\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  188 | GLW: sid 189\n",
      "\u001b[?25lMerging daily equity files:  [----------#-------------------------]  189 | GM: sid 190\n",
      "\u001b[?25lLoading custom pricing data:   [##############----------------------]   40%  0d 00:00:12 | GOOGL: sid 191\n",
      "\u001b[?25lLoading custom pricing data:   [##############----------------------]   41%  0d 00:00:12 | GPC: sid 192\n",
      "\u001b[?25lMerging daily equity files:  [--------#---------------------------]  192 | GPN: sid 193\n",
      "\u001b[?25lMerging daily equity files:  [-------#----------------------------]  193 | GPS: sid 194\n",
      "\u001b[?25lLoading custom pricing data:   [###############---------------------]   41%  0d 00:00:12 | GRMN: sid 195\n",
      "\u001b[?25lLoading custom pricing data:   [###############---------------------]   42%  0d 00:00:12 | GS: sid 196\n",
      "\u001b[?25lMerging daily equity files:  [-----#------------------------------]  196 | GWW: sid 197\n",
      "\u001b[?25lMerging daily equity files:  [-----#------------------------------]  197 | HAL: sid 198\n",
      "\u001b[?25lMerging daily equity files:  [----#-------------------------------]  198 | HAS: sid 199\n",
      "\u001b[?25lMerging daily equity files:  [----#-------------------------------]  199 | HBAN: sid 200\n",
      "\u001b[?25lLoading custom pricing data:   [###############---------------------]   43%  0d 00:00:12 | HBI: sid 201\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  201 | HCA: sid 202\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  202 | HCP: sid 203\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  203 | HD: sid 204\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  204 | HES: sid 205\n",
      "\u001b[?25lLoading custom pricing data:   [###############---------------------]   44%  0d 00:00:12 | HFC: sid 206\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  206 | HIG: sid 207\n",
      "\u001b[?25lLoading custom pricing data:   [################--------------------]   44%  0d 00:00:12 | HII: sid 208\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  208 | HOG: sid 209\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  209 | HOLX: sid 210\n",
      "\u001b[?25lLoading custom pricing data:   [################--------------------]   45%  0d 00:00:12 | HON: sid 211\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  211 | HP: sid 212\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  212 | HPQ: sid 213\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  213 | HRB: sid 214\n",
      "\u001b[?25lLoading custom pricing data:   [################--------------------]   46%  0d 00:00:12 | HRL: sid 215\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  215 | HRS: sid 216\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  216 | HSIC: sid 217\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  217 | HST: sid 218\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  218 | HSY: sid 219\n",
      "\u001b[?25lLoading custom pricing data:   [################--------------------]   47%  0d 00:00:11 | HUM: sid 220\n",
      "\u001b[?25lLoading custom pricing data:   [#################-------------------]   47%  0d 00:00:11 | IBM: sid 221\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  221 | ICE: sid 222\n",
      "\u001b[?25lMerging daily equity files:  [---#--------------------------------]  222 | IDXX: sid 223\n",
      "\u001b[?25lMerging daily equity files:  [----#-------------------------------]  223 | IFF: sid 224\n",
      "\u001b[?25lLoading custom pricing data:   [#################-------------------]   48%  0d 00:00:11 | ILMN: sid 225\n",
      "\u001b[?25lMerging daily equity files:  [-----#------------------------------]  225 | INCY: sid 226\n",
      "\u001b[?25lMerging daily equity files:  [-----#------------------------------]  226 | INTC: sid 227\n",
      "\u001b[?25lMerging daily equity files:  [------#-----------------------------]  227 | INTU: sid 228\n",
      "\u001b[?25lLoading custom pricing data:   [#################-------------------]   49%  0d 00:00:11 | IP: sid 229\n",
      "\u001b[?25lMerging daily equity files:  [-------#----------------------------]  229 | IPG: sid 230\n",
      "\u001b[?25lMerging daily equity files:  [--------#---------------------------]  230 | IPGP: sid 231\n",
      "\u001b[?25lMerging daily equity files:  [--------#---------------------------]  231 | IR: sid 232\n",
      "\u001b[?25lMerging daily equity files:  [---------#--------------------------]  232 | IRM: sid 233\n",
      "\u001b[?25lLoading custom pricing data:   [##################------------------]   50%  0d 00:00:11 | ISRG: sid 234\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  234 | IT: sid 235\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  235 | ITW: sid 236\n",
      "\u001b[?25lMerging daily equity files:  [------------#-----------------------]  236 | IVZ: sid 237\n",
      "\u001b[?25lMerging daily equity files:  [-------------#----------------------]  237 | JBHT: sid 238\n",
      "\u001b[?25lLoading custom pricing data:   [##################------------------]   51%  0d 00:00:11 | JCI: sid 239\n",
      "\u001b[?25lMerging daily equity files:  [---------------#--------------------]  239 | JEC: sid 240\n",
      "\u001b[?25lMerging daily equity files:  [---------------#--------------------]  240 | JEF: sid 241\n",
      "\u001b[?25lMerging daily equity files:  [----------------#-------------------]  241 | JKHY: sid 242\n",
      "\u001b[?25lLoading custom pricing data:   [##################------------------]   52%  0d 00:00:11 | JNJ: sid 243\n",
      "\u001b[?25lMerging daily equity files:  [------------------#-----------------]  243 | JNPR: sid 244\n",
      "\u001b[?25lMerging daily equity files:  [-------------------#----------------]  244 | JPM: sid 245\n",
      "\u001b[?25lLoading custom pricing data:   [##################------------------]   52%  0d 00:00:10 | JWN: sid 246\n",
      "\u001b[?25lLoading custom pricing data:   [###################-----------------]   52%  0d 00:00:10 | K: sid 247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lLoading custom pricing data:   [###################-----------------]   53%  0d 00:00:10 | KEY: sid 248\n",
      "\u001b[?25lMerging daily equity files:  [----------------------#-------------]  248 | KIM: sid 249\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------#----------]  249 | KLAC: sid 250\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------#---------]  250 | KMB: sid 251\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------#---------]  251 | KMI: sid 252\n",
      "\u001b[?25lLoading custom pricing data:   [###################-----------------]   54%  0d 00:00:10 | KMX: sid 253\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------#-------]  253 | KO: sid 254\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------#-------]  254 | KR: sid 255\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------#------]  255 | KSS: sid 256\n",
      "\u001b[?25lLoading custom pricing data:   [###################-----------------]   55%  0d 00:00:10 | KSU: sid 257\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------#-----]  257 | L: sid 258\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  258 | LB: sid 259\n",
      "\u001b[?25lLoading custom pricing data:   [####################----------------]   55%  0d 00:00:10 | LEG: sid 260\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------------#---]  260 | LEN: sid 261\n",
      "\u001b[?25lLoading custom pricing data:   [####################----------------]   56%  0d 00:00:10 | LH: sid 262\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  262 | LKQ: sid 263\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  263 | LLL: sid 264\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  264 | LLY: sid 265\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  265 | LMT: sid 266\n",
      "\u001b[?25lLoading custom pricing data:   [####################----------------]   57%  0d 00:00:10 | LNC: sid 267\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  267 | LNT: sid 268\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  268 | LOW: sid 269\n",
      "\u001b[?25lLoading custom pricing data:   [####################----------------]   57%  0d 00:00:09 | LRCX: sid 270\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  270 | LUV: sid 271\n",
      "\u001b[?25lLoading custom pricing data:   [####################----------------]   58%  0d 00:00:09 | LYB: sid 272\n",
      "\u001b[?25lLoading custom pricing data:   [#####################---------------]   58%  0d 00:00:09 | M: sid 273\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  273 | MA: sid 274\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  274 | MAA: sid 275\n",
      "\u001b[?25lLoading custom pricing data:   [#####################---------------]   59%  0d 00:00:09 | MAC: sid 276\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  276 | MAR: sid 277\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  277 | MAS: sid 278\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  278 | MAT: sid 279\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  279 | MCD: sid 280\n",
      "\u001b[?25lLoading custom pricing data:   [#####################---------------]   60%  0d 00:00:09 | MCHP: sid 281\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  281 | MCK: sid 282\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  282 | MCO: sid 283\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  283 | MDLZ: sid 284\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  284 | MDT: sid 285\n",
      "\u001b[?25lLoading custom pricing data:   [######################--------------]   61%  0d 00:00:09 | MET: sid 286\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  286 | MGM: sid 287\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  287 | MHK: sid 288\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  288 | MKC: sid 289\n",
      "\u001b[?25lLoading custom pricing data:   [######################--------------]   62%  0d 00:00:09 | MLM: sid 290\n",
      "\u001b[?25lLoading custom pricing data:   [######################--------------]   62%  0d 00:00:08 | MMC: sid 291\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------------#---]  291 | MMM: sid 292\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  292 | MNST: sid 293\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------#-----]  293 | MO: sid 294\n",
      "\u001b[?25lLoading custom pricing data:   [######################--------------]   63%  0d 00:00:08 | MOS: sid 295\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------#------]  295 | MPC: sid 296\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------#------]  296 | MRK: sid 297\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------#-------]  297 | MRO: sid 298\n",
      "\u001b[?25lLoading custom pricing data:   [#######################-------------]   63%  0d 00:00:08 | MS: sid 299\n",
      "\u001b[?25lLoading custom pricing data:   [#######################-------------]   64%  0d 00:00:08 | MSCI: sid 300\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------#---------]  300 | MSFT: sid 301\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------#----------]  301 | MSI: sid 302\n",
      "\u001b[?25lMerging daily equity files:  [------------------------#-----------]  302 | MTB: sid 303\n",
      "\u001b[?25lLoading custom pricing data:   [#######################-------------]   65%  0d 00:00:08 | MTD: sid 304\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------#------------]  304 | MU: sid 305\n",
      "\u001b[?25lMerging daily equity files:  [----------------------#-------------]  305 | MXIM: sid 306\n",
      "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  306 | MYL: sid 307\n",
      "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  307 | NBL: sid 308\n",
      "\u001b[?25lLoading custom pricing data:   [#######################-------------]   66%  0d 00:00:08 | NDAQ: sid 309\n",
      "\u001b[?25lMerging daily equity files:  [-------------------#----------------]  309 | NEE: sid 310\n",
      "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  310 | NEM: sid 311\n",
      "\u001b[?25lLoading custom pricing data:   [########################------------]   66%  0d 00:00:08 | NFLX: sid 312\n",
      "\u001b[?25lLoading custom pricing data:   [########################------------]   66%  0d 00:00:07 | NI: sid 313\n",
      "\u001b[?25lLoading custom pricing data:   [########################------------]   67%  0d 00:00:07 | NKE: sid 314\n",
      "\u001b[?25lMerging daily equity files:  [------------------#-----------------]  314 | NKTR: sid 315\n",
      "\u001b[?25lMerging daily equity files:  [-----------------#------------------]  315 | NLSN: sid 316\n",
      "\u001b[?25lMerging daily equity files:  [----------------#-------------------]  316 | NOC: sid 317\n",
      "\u001b[?25lLoading custom pricing data:   [########################------------]   68%  0d 00:00:07 | NOV: sid 318\n",
      "\u001b[?25lMerging daily equity files:  [---------------#--------------------]  318 | NRG: sid 319\n",
      "\u001b[?25lMerging daily equity files:  [--------------#---------------------]  319 | NSC: sid 320\n",
      "\u001b[?25lMerging daily equity files:  [-------------#----------------------]  320 | NTAP: sid 321\n",
      "\u001b[?25lMerging daily equity files:  [------------#-----------------------]  321 | NTRS: sid 322\n",
      "\u001b[?25lLoading custom pricing data:   [########################------------]   69%  0d 00:00:07 | NUE: sid 323\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  323 | NVDA: sid 324\n",
      "\u001b[?25lLoading custom pricing data:   [#########################-----------]   69%  0d 00:00:07 | NWL: sid 325\n",
      "\u001b[?25lMerging daily equity files:  [---------#--------------------------]  325 | O: sid 326\n",
      "\u001b[?25lMerging daily equity files:  [---------#--------------------------]  326 | OKE: sid 327\n",
      "\u001b[?25lLoading custom pricing data:   [#########################-----------]   70%  0d 00:00:07 | OMC: sid 328\n",
      "\u001b[?25lMerging daily equity files:  [-------#----------------------------]  328 | ORCL: sid 329\n",
      "\u001b[?25lMerging daily equity files:  [-------#----------------------------]  329 | ORLY: sid 330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lMerging daily equity files:  [------#-----------------------------]  330 | OXY: sid 331\n",
      "\u001b[?25lLoading custom pricing data:   [#########################-----------]   71%  0d 00:00:07 | PAYX: sid 332\n",
      "\u001b[?25lMerging daily equity files:  [-----#------------------------------]  332 | PBCT: sid 333\n",
      "\u001b[?25lLoading custom pricing data:   [#########################-----------]   71%  0d 00:00:06 | PCAR: sid 334\n",
      "\u001b[?25lMerging daily equity files:  [----#-------------------------------]  334 | PEG: sid 335\n",
      "\u001b[?25lMerging daily equity files:  [---#--------------------------------]  335 | PEP: sid 336\n",
      "\u001b[?25lLoading custom pricing data:   [#########################-----------]   72%  0d 00:00:06 | PFE: sid 337\n",
      "\u001b[?25lLoading custom pricing data:   [##########################----------]   72%  0d 00:00:06 | PFG: sid 338\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  338 | PG: sid 339\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  339 | PGR: sid 340\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  340 | PH: sid 341\n",
      "\u001b[?25lLoading custom pricing data:   [##########################----------]   73%  0d 00:00:06 | PHM: sid 342\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  342 | PKG: sid 343\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  343 | PKI: sid 344\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  344 | PLD: sid 345\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  345 | PM: sid 346\n",
      "\u001b[?25lLoading custom pricing data:   [##########################----------]   74%  0d 00:00:06 | PNC: sid 347\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  347 | PNR: sid 348\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  348 | PNW: sid 349\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  349 | PPG: sid 350\n",
      "\u001b[?25lLoading custom pricing data:   [###########################---------]   75%  0d 00:00:06 | PPL: sid 351\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  351 | PRGO: sid 352\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  352 | PRU: sid 353\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  353 | PSA: sid 354\n",
      "\u001b[?25lLoading custom pricing data:   [###########################---------]   75%  0d 00:00:05 | PSX: sid 355\n",
      "\u001b[?25lLoading custom pricing data:   [###########################---------]   76%  0d 00:00:05 | PVH: sid 356\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  356 | PWR: sid 357\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  357 | PXD: sid 358\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  358 | QCOM: sid 359\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  359 | RCL: sid 360\n",
      "\u001b[?25lLoading custom pricing data:   [###########################---------]   77%  0d 00:00:05 | RE: sid 361\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  361 | REG: sid 362\n",
      "\u001b[?25lMerging daily equity files:  [#-----------------------------------]  362 | REGN: sid 363\n",
      "\u001b[?25lLoading custom pricing data:   [############################--------]   77%  0d 00:00:05 | RF: sid 364\n",
      "\u001b[?25lLoading custom pricing data:   [############################--------]   78%  0d 00:00:05 | RHI: sid 365\n",
      "\u001b[?25lMerging daily equity files:  [-#----------------------------------]  365 | RHT: sid 366\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  366 | RJF: sid 367\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  367 | RL: sid 368\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  368 | RMD: sid 369\n",
      "\u001b[?25lLoading custom pricing data:   [############################--------]   79%  0d 00:00:05 | ROK: sid 370\n",
      "\u001b[?25lMerging daily equity files:  [---#--------------------------------]  370 | ROL: sid 371\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  371 | ROP: sid 372\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  372 | ROST: sid 373\n",
      "\u001b[?25lMerging daily equity files:  [--#---------------------------------]  373 | RSG: sid 374\n",
      "\u001b[?25lLoading custom pricing data:   [############################--------]   80%  0d 00:00:05 | RTN: sid 375\n",
      "\u001b[?25lLoading custom pricing data:   [############################--------]   80%  0d 00:00:04 | SBAC: sid 376\n",
      "\u001b[?25lLoading custom pricing data:   [#############################-------]   80%  0d 00:00:04 | SBUX: sid 377\n",
      "\u001b[?25lMerging daily equity files:  [----#-------------------------------]  377 | SCHW: sid 378\n",
      "\u001b[?25lLoading custom pricing data:   [#############################-------]   81%  0d 00:00:04 | SEE: sid 379\n",
      "\u001b[?25lMerging daily equity files:  [-----#------------------------------]  379 | SHW: sid 380\n",
      "\u001b[?25lMerging daily equity files:  [------#-----------------------------]  380 | SIVB: sid 381\n",
      "\u001b[?25lMerging daily equity files:  [-------#----------------------------]  381 | SJM: sid 382\n",
      "\u001b[?25lMerging daily equity files:  [-------#----------------------------]  382 | SLB: sid 383\n",
      "\u001b[?25lLoading custom pricing data:   [#############################-------]   82%  0d 00:00:04 | SLG: sid 384\n",
      "\u001b[?25lMerging daily equity files:  [---------#--------------------------]  384 | SNA: sid 385\n",
      "\u001b[?25lMerging daily equity files:  [---------#--------------------------]  385 | SNPS: sid 386\n",
      "\u001b[?25lMerging daily equity files:  [----------#-------------------------]  386 | SO: sid 387\n",
      "\u001b[?25lMerging daily equity files:  [-----------#------------------------]  387 | SPG: sid 388\n",
      "\u001b[?25lLoading custom pricing data:   [#############################-------]   83%  0d 00:00:04 | SPGI: sid 389\n",
      "\u001b[?25lLoading custom pricing data:   [##############################------]   83%  0d 00:00:04 | SRE: sid 390\n",
      "\u001b[?25lMerging daily equity files:  [-------------#----------------------]  390 | STI: sid 391\n",
      "\u001b[?25lMerging daily equity files:  [--------------#---------------------]  391 | STT: sid 392\n",
      "\u001b[?25lLoading custom pricing data:   [##############################------]   84%  0d 00:00:04 | STX: sid 393\n",
      "\u001b[?25lMerging daily equity files:  [---------------#--------------------]  393 | STZ: sid 394\n",
      "\u001b[?25lMerging daily equity files:  [----------------#-------------------]  394 | SWK: sid 395\n",
      "\u001b[?25lMerging daily equity files:  [-----------------#------------------]  395 | SWKS: sid 396\n",
      "\u001b[?25lMerging daily equity files:  [------------------#-----------------]  396 | SYK: sid 397\n",
      "\u001b[?25lLoading custom pricing data:   [##############################------]   85%  0d 00:00:04 | SYMC: sid 398\n",
      "\u001b[?25lLoading custom pricing data:   [##############################------]   85%  0d 00:00:03 | SYY: sid 399\n",
      "\u001b[?25lMerging daily equity files:  [--------------------#---------------]  399 | T: sid 400\n",
      "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  400 | TAP: sid 401\n",
      "\u001b[?25lMerging daily equity files:  [---------------------#--------------]  401 | TDG: sid 402\n",
      "\u001b[?25lLoading custom pricing data:   [###############################-----]   86%  0d 00:00:03 | TEL: sid 403\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------#------------]  403 | TFX: sid 404\n",
      "\u001b[?25lMerging daily equity files:  [------------------------#-----------]  404 | TGT: sid 405\n",
      "\u001b[?25lMerging daily equity files:  [-------------------#----------------]  405 | TIF: sid 406\n",
      "\u001b[?25lMerging daily equity files:  [--------------------#---------------]  406 | TJX: sid 407\n",
      "\u001b[?25lLoading custom pricing data:   [###############################-----]   87%  0d 00:00:03 | TMK: sid 408\n",
      "\u001b[?25lMerging daily equity files:  [----------------------#-------------]  408 | TMO: sid 409\n",
      "\u001b[?25lMerging daily equity files:  [----------------------#-------------]  409 | TPR: sid 410\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------#------------]  410 | TRIP: sid 411\n",
      "\u001b[?25lLoading custom pricing data:   [###############################-----]   88%  0d 00:00:03 | TROW: sid 412\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------#----------]  412 | TRV: sid 413\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------#----------]  413 | TSCO: sid 414\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------#---------]  414 | TSN: sid 415\n",
      "\u001b[?25lLoading custom pricing data:   [################################----]   88%  0d 00:00:03 | TSS: sid 416\n",
      "\u001b[?25lLoading custom pricing data:   [################################----]   89%  0d 00:00:03 | TTWO: sid 417\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------#-------]  417 | TXN: sid 418\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------#------]  418 | TXT: sid 419\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------#------]  419 | UAA: sid 420\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------#-----]  420 | UAL: sid 421\n",
      "\u001b[?25lLoading custom pricing data:   [################################----]   90%  0d 00:00:02 | UDR: sid 422\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  422 | UHS: sid 423\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  423 | ULTA: sid 424\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------------#---]  424 | UNH: sid 425\n",
      "\u001b[?25lLoading custom pricing data:   [################################----]   91%  0d 00:00:02 | UNM: sid 426\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  426 | UNP: sid 427\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  427 | UPS: sid 428\n",
      "\u001b[?25lLoading custom pricing data:   [#################################---]   91%  0d 00:00:02 | URI: sid 429\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  429 | USB: sid 430\n",
      "\u001b[?25lLoading custom pricing data:   [#################################---]   92%  0d 00:00:02 | UTX: sid 431\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  431 | V: sid 432\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  432 | VAR: sid 433\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  433 | VFC: sid 434\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  434 | VIAB: sid 435\n",
      "\u001b[?25lLoading custom pricing data:   [#################################---]   93%  0d 00:00:02 | VLO: sid 436\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  436 | VMC: sid 437\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  437 | VNO: sid 438\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  438 | VRSK: sid 439\n",
      "\u001b[?25lLoading custom pricing data:   [#################################---]   94%  0d 00:00:02 | VRSN: sid 440\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  440 | VRTX: sid 441\n",
      "\u001b[?25lLoading custom pricing data:   [##################################--]   94%  0d 00:00:02 | VTR: sid 442\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  442 | VZ: sid 443\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  443 | WAB: sid 444\n",
      "\u001b[?25lLoading custom pricing data:   [##################################--]   95%  0d 00:00:01 | WAT: sid 445\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  445 | WBA: sid 446\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  446 | WCG: sid 447\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  447 | WDC: sid 448\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  448 | WEC: sid 449\n",
      "\u001b[?25lLoading custom pricing data:   [##################################--]   96%  0d 00:00:01 | WELL: sid 450\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  450 | WFC: sid 451\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  451 | WHR: sid 452\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  452 | WM: sid 453\n",
      "\u001b[?25lLoading custom pricing data:   [##################################--]   97%  0d 00:00:01 | WMB: sid 454\n",
      "\u001b[?25lLoading custom pricing data:   [###################################-]   97%  0d 00:00:01 | WMT: sid 455\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  455 | WU: sid 456\n",
      "\u001b[?25lMerging daily equity files:  [-----------------------------------#]  456 | WY: sid 457\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  457 | WYNN: sid 458\n",
      "\u001b[?25lLoading custom pricing data:   [###################################-]   98%  0d 00:00:01 | XEC: sid 459\n",
      "\u001b[?25lMerging daily equity files:  [----------------------------------#-]  459 | XEL: sid 460\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  460 | XLNX: sid 461\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  461 | XOM: sid 462\n",
      "\u001b[?25lMerging daily equity files:  [---------------------------------#--]  462 | XRAY: sid 463\n",
      "\u001b[?25lLoading custom pricing data:   [###################################-]   99%  0d 00:00:01 | XRX: sid 464\n",
      "\u001b[?25lMerging daily equity files:  [--------------------------------#---]  464 | XYL: sid 465\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  465 | YUM: sid 466\n",
      "\u001b[?25lMerging daily equity files:  [-------------------------------#----]  466 | ZBH: sid 467\n",
      "\u001b[?25lLoading custom pricing data:   [####################################]  100%              | ZION: sid 468\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------#-----]  468\u001b[?25h\n",
      "\u001b[?25lMerging daily equity files:  [####################################]     \u001b[?25h\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/zipline/data/us_equity_pricing.py:931: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not issubdtype(actual, expected):\n"
     ]
    }
   ],
   "source": [
    "!zipline ingest -b custom-csvdir-bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, meta_data = ts.get_daily_adjusted('APTV', outputsize='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'volume', 'dividend', 'split'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('csvdir_processed/daily/{}.csv'.format(ticker))\n",
    "df.set_index('date', inplace=True)\n",
    "df.columns\n",
    "# df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('csvdir_processed/daily/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/empyrical/utils.py:32: UserWarning: Unable to import pandas_datareader. Suppressing import error and continuing. All data reading functionality will raise errors; but has been deprecated and will be removed in a later version.\n",
      "  warnings.warn(msg)\n",
      "\u001b[?25lLoading custom pricing data:   [####################################]  100% | MMM: sid 0\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  0\u001b[?25h\n",
      "\u001b[?25lMerging daily equity files:  [####################################]   \u001b[?25h\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/zipline/data/us_equity_pricing.py:931: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not issubdtype(actual, expected):\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/empyrical/utils.py:32: UserWarning: Unable to import pandas_datareader. Suppressing import error and continuing. All data reading functionality will raise errors; but has been deprecated and will be removed in a later version.\n",
      "  warnings.warn(msg)\n",
      "\u001b[?25lLoading custom pricing data:   [####################################]  100% | ABT: sid 0\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  0\u001b[?25h\n",
      "\u001b[?25lMerging daily equity files:  [####################################]   \u001b[?25h\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/zipline/data/us_equity_pricing.py:931: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not issubdtype(actual, expected):\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/empyrical/utils.py:32: UserWarning: Unable to import pandas_datareader. Suppressing import error and continuing. All data reading functionality will raise errors; but has been deprecated and will be removed in a later version.\n",
      "  warnings.warn(msg)\n",
      "\u001b[?25lLoading custom pricing data:   [####################################]  100% | ABBV: sid 0\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  0\u001b[?25h\n",
      "\u001b[?25lMerging daily equity files:  [####################################]   \u001b[?25h\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/zipline/data/us_equity_pricing.py:931: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not issubdtype(actual, expected):\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/empyrical/utils.py:32: UserWarning: Unable to import pandas_datareader. Suppressing import error and continuing. All data reading functionality will raise errors; but has been deprecated and will be removed in a later version.\n",
      "  warnings.warn(msg)\n",
      "\u001b[?25lLoading custom pricing data:   [####################################]  100% | ABMD: sid 0\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  0\u001b[?25h\n",
      "\u001b[?25lMerging daily equity files:  [####################################]   \u001b[?25h\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/zipline/data/us_equity_pricing.py:931: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not issubdtype(actual, expected):\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/empyrical/utils.py:32: UserWarning: Unable to import pandas_datareader. Suppressing import error and continuing. All data reading functionality will raise errors; but has been deprecated and will be removed in a later version.\n",
      "  warnings.warn(msg)\n",
      "\u001b[?25lLoading custom pricing data:   [####################################]  100% | ACN: sid 0\n",
      "\u001b[?25lMerging daily equity files:  [------------------------------------]  0\u001b[?25h\n",
      "\u001b[?25lMerging daily equity files:  [####################################]   \u001b[?25h\n",
      "/Users/leehongkai/anaconda/envs/trading/lib/python3.5/site-packages/zipline/data/us_equity_pricing.py:931: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not issubdtype(actual, expected):\n"
     ]
    }
   ],
   "source": [
    "with open('sp500ticker.pickle', 'rb') as f:\n",
    "    tickers = pickle.load(f)\n",
    "\n",
    "\n",
    "for ticker in ['combined_sp500', ]:\n",
    "    # resolve discordance of the BF.B ticker naming between wikipedia and AV\n",
    "    \n",
    "    if ticker == 'BF.B':\n",
    "        ticker = 'BF-B'\n",
    "#     process_raw_data(ticker)\n",
    "    ingest_by_zipline(ticker, delta=1)\n",
    "    shutil.copyfile('csvdir_processed/daily/{}.csv'.format(ticker), 'csvdir_processed_temp/daily/{}.csv'.format(ticker))  \n",
    "    !zipline ingest -b custom-csvdir-bundle\n",
    "    os.unlink('csvdir_processed_temp/daily/{}.csv'.format(ticker))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2001-01-05 00:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp('2001-01-05', tz='utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyse = mcal.get_calendar('NYSE')\n",
    "early = nyse.schedule(start_date='2019-07-01', end_date='2019-07-10')\n",
    "date1 = mcal.date_range(early, frequency='1D').strftime('%Y-%m-%d')[5]\n",
    "date1\n",
    "itemindex = np.where(mcal.date_range(early, frequency='1D').strftime('%Y-%m-%d')==date1)\n",
    "\n",
    "itemindex[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get_data()\n",
    "# sleep(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('eod_alphavantage/{}.csv'.format('AAPL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "def compile_data():\n",
    "    \n",
    "    with open('sp500ticker.pickle', 'rb') as f:\n",
    "        tickers = pickle.load(f)\n",
    "        \n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    for count, ticker in enumerate(tickers):\n",
    "        if ticker + '.csv' in os.listdir('stock_dfs'):\n",
    "            df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "            df.set_index('date', inplace=True)\n",
    "            df.rename(columns={'close':ticker}, inplace=True)\n",
    "            df.drop(['open', 'high', 'low', 'volume'], 1, inplace=True)\n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how='outer', lsuffix='_left', rsuffix='_right')\n",
    "  \n",
    "        if count % 10 == 0:\n",
    "            print(count)\n",
    "    \n",
    "    \n",
    "    main_df.to_csv('sp500_joined_closes.csv')\n",
    "    \n",
    "compile_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>MMM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>...</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XL</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2018-08-23</td>\n",
       "      <td>202.75</td>\n",
       "      <td>65.83</td>\n",
       "      <td>97.15</td>\n",
       "      <td>376.93</td>\n",
       "      <td>165.2</td>\n",
       "      <td>71.17</td>\n",
       "      <td>257.0</td>\n",
       "      <td>22.29</td>\n",
       "      <td>163.26</td>\n",
       "      <td>...</td>\n",
       "      <td>145.14</td>\n",
       "      <td>47.69</td>\n",
       "      <td>27.45</td>\n",
       "      <td>73.16</td>\n",
       "      <td>56.95</td>\n",
       "      <td>74.6942</td>\n",
       "      <td>83.52</td>\n",
       "      <td>124.48</td>\n",
       "      <td>53.58</td>\n",
       "      <td>89.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     MMM    ABT   ABBV    ABMD    ACN   ATVI   ADBE    AMD  \\\n",
       "1255  2018-08-23  202.75  65.83  97.15  376.93  165.2  71.17  257.0  22.29   \n",
       "\n",
       "         AAP  ...      WYNN    XEL    XRX   XLNX     XL      XYL    YUM  \\\n",
       "1255  163.26  ...    145.14  47.69  27.45  73.16  56.95  74.6942  83.52   \n",
       "\n",
       "         ZBH   ZION    ZTS  \n",
       "1255  124.48  53.58  89.67  \n",
       "\n",
       "[1 rows x 506 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.read_csv('sp500_joined_closes.csv')\n",
    "main_df = main_df[457:]\n",
    "main_df.isnull().any()\n",
    "main_df[-1:]\n",
    "# with open('sp500ticker.pickle', 'rb') as f:\n",
    "#     tickers = pickle.load(f)\n",
    "    \n",
    "# len(set(tickers))\n",
    "# tickers_sqlcolumn = ' real, '.join(str(x) for x in tickers)\n",
    "# tickers_sqlcolumn = '(date int, ' + tickers_sqlcolumn + ' real)'\n",
    "# tickers_sqlcolumn = tickers_sqlcolumn.replace('.', '_')\n",
    "# tickers_sqlcolumn = tickers_sqlcolumn.replace('ALL ', 'ALL_1 ')\n",
    "\n",
    "\n",
    "# makedb('dbase_Sqlite', 'SP500',  tickers_sqlcolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(202.75,)]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite://///Users/leehongkai/Google Drive/FinancialAnalyses/Quant-Finance/sqlite_finance.db')\n",
    "\n",
    "main_df.to_sql('SP500', con=engine)\n",
    "engine.execute(\"SELECT MMM FROM SP500 where date=='2018-08-23'\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data_for_labels(ticker):\n",
    "    hm_days = 7\n",
    "    df = pd.read_csv('sp500_joined_closes.csv', index_col=0)\n",
    "    tickers = df.columns.values.tolist()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    for i in range(1, hm_days+1):\n",
    "        df['{}_{}d'.format(ticker, i)] = (df[ticker].shift(-1) - df[ticker]) / df[ticker]\n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "    return tickers, df\n",
    "\n",
    "def buy_sell_hold(*args):\n",
    "    cols = [c for c in args]\n",
    "    requirement = 0.02\n",
    "    for col in cols:\n",
    "        if col > requirement:\n",
    "            return 1\n",
    "        if col < -requirement:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_featuresets(ticker):\n",
    "    \n",
    "    tickers, df = process_data_for_labels(ticker)\n",
    "    \n",
    "    df['{}_target'.format(ticker)] = list(map(buy_sell_hold, \n",
    "                                              df['{}_1d'.format(ticker)],\n",
    "                                              df['{}_2d'.format(ticker)],\n",
    "                                              df['{}_3d'.format(ticker)],\n",
    "                                              df['{}_4d'.format(ticker)],\n",
    "                                              df['{}_5d'.format(ticker)],\n",
    "                                              df['{}_6d'.format(ticker)],\n",
    "                                              df['{}_7d'.format(ticker)],\n",
    "                                             ))\n",
    "    \n",
    "    vals = df['{}_target'.format(ticker)].values.tolist()\n",
    "    str_vals = [str(i) for i in vals]\n",
    "    print('Data spread: ', Counter(str_vals))\n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df_vals = df[[ticker for ticker in tickers]].pct_change()\n",
    "    df_vals = df_vals.replace([np.inf, -np.inf], 0)\n",
    "    df_vals.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df_vals.values\n",
    "    y = df['{}_target'.format(ticker)].values\n",
    "    \n",
    "    return X, y, df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
